==============================================
音響学会
==============================================


印象表現語ラベルを用いた Fader Networks に基づく音声印象変換
============================================================

ひとこと
---------------------
FaderNetVCの話者ラベルを印象ラベルに変えたやつ。印象ラベルの数値を変えることでその印象の声に変換する。


変換結果はうまく行ってない。
人によって印象に対するステレオタイプが違うからうまく学習できないのでは？という結論

わしの感想
---------------------
変換音声そのもののクオリティが良くないから結論をつけるには早計ではと思った。
モデル学習そのものの精錬をしたほうが良いと感じる

私の研究におけるデータセット作成時に、被験者属性を絞る必要性があると考えることができる。

関連研究
---------------------
FaderNetVCの改良案
同じグループの研究
FaderNetについて詳しく書いているため、こちらも参考にするべき

https://www.ieice.org/ken/paper/20210619TCe4/

軽いFaderNetの説明
^^^^^^^^^^^^^^^^^^^^^
CVAEのlatentにDiscriminaterを噛ませるモデル

Discriminaterにlabel判別させることにより、latentからlabelの要素を排除することができる

よってDecoderに入力されるlatentがcontentのみを表現できるようにする狙いがある

深層学習に基づく音声合成における顔画像情報を用いたクロスモーダル話者適応
==============================================================================

ひとこと
-------------------
VAEベースの音声合成と画像生成器を同時学習。imageとspeech双方のlatent distributionが近づくように学習することで相互にlatentを利用できる。
つまり画像から音声、音声から画像が生成できる。

わしの感想
--------------------
この研究の着想はFace2speechとCrossmodal VCの両方だと思われる。
双方の特徴を合わせて発展させた内容だと感じた

lossのとり方がすごく特徴的だと感じる。
音声のlatentが非時系列なので、私自身の研究に適応するには工夫が必要

関連研究
---------------------
https://github.com/DeNA/Face2Speech

http://www.kecl.ntt.co.jp/people/kameoka.hirokazu/Demos/crossmodal-vc/


マルチモーダルVAEを用いた顔画像に基づく目標話者音声不要な声質変換
==============================================================================

ひとこと
--------------------------------
CVAEのVCのlabelとしてFaceNetの出力を利用。

わしの感想
--------------------------------
新規性がマジでない。crossmodalVCの劣化のように感じる。
先行研究調査も足りてなさそうだったので、こうならないよう戒めとしたい。

この研究において、本当の顔と声のペアと印象があった顔と声のペアが違うよねって指摘があった。
私の研究においてもそこが重要だと思われるのでしっかり考えていきたい。
