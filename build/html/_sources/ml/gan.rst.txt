===============================
Generative adversarial network
===============================

https://www.bigdata-navi.com/aidrops/2519/

https://dreamer-uma.com/gan-theory/

疑問
==================
.. math::
<<<<<<< HEAD
	\mathbb{E}_{x\sim p(x)}[\ln D(x;\phi)]

	\underset{x\sim p}{\mathbb{E}}[\ln D(x;\phi)]

	\mathbb{E}_{p(x)}[\ln D(x;\phi)]

全部一緒っぽい

=======
	\mathbf{E}_{x\sim p(x)}[\ln D(x;\phi)]

	\underset{x\sim p}{\mathbf{E}}[\ln D(x;\phi)]

	\mathbf{E}_{p(x)}[\ln D(x;\phi)]

全部一緒っぽい

違うかも

>>>>>>> 2783ffa775bb93c1c7f0aa2a2fefd9086c1ab936

導出
==================
確率変数 :math:`x` に対し、データ分布を :math:`p_d(x)` 、モデル分布を :math:`p_g(x)` で表す。

分布 :math:`p_d(x)` は分布の形が明示されているわけではないため、どのような分布か分からず、直接尤度を計算することはできない。

よって天下り的(だと思ったが違うかもしれない)ではあるが、

.. math::
	\underset{G}{\min}\underset{D}{\max}V(D, G)
<<<<<<< HEAD
=======

なんか
===================
確率変数 :math:`\mathbf{x} \in \mathbb{R}_c, \mathbf{y} \in \mathbb{R}_d` において、真の確率分布 :math:`P(\mathbf{x}, \mathbf{y})` と近似分布 :math:`Q(\mathbf{x}, \mathbf{y})` を定めたとき、これの交差エントロピーは

.. math::
        H(P(\mathbf{x}, \mathbf{y}), Q(\mathbf{x}, \mathbf{y})) &= -\int_{\mathbb{R}_d}\int_{\mathbb{R}_c}P(\mathbf{x}, \mathbf{y})\log Q(\mathbf{x}, \mathbf{y}) d\mathbf{x}d\mathbf{y} \\
   &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{x}, \mathbf{y})] \\
   &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{y}|\mathbf{x})Q(\mathbf{x})] \\
   &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{y}|\mathbf{x})] + \underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{x})]\\
   &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{y}|\mathbf{x})] + \underset{P(\mathbf{x})}{\mathbf{E}}[\log Q(\mathbf{x})]\\
   &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log Q(\mathbf{y}|\mathbf{x})] + H(P(\mathbf{x}),Q(\mathbf{x}))\\

ここでDiscriminatorを :math:`D(\mathbf{x})` とし、 :math:`Q(\mathbf{y}|\mathbf{x}) = \mathrm{Bern}(\mathbf{y}|D(\mathbf{x}))` を仮定すると、

.. math::
        H(P(\mathbf{x}, \mathbf{y}), Q(\mathbf{x}, \mathbf{y})) &= -\underset{P(\mathbf{x}, \mathbf{y})}{\mathbf{E}}[\log \mathrm{Bern}(\mathbf{y}|D(\mathbf{x}))] + H(P(\mathbf{x}),Q(\mathbf{x}))\\
   &= -\underset{P(\mathbf{x}|\mathbf{y})P(\mathbf{y})}{\mathbf{E}}[\log \mathrm{Bern}(\mathbf{y}|D(\mathbf{x}))] + H(P(\mathbf{x}),Q(\mathbf{x}))\\
   &= -\underset{P(\mathbf{x}|\mathbf{y=0})P(\mathbf{y=0})}{\mathbf{E}}[\log \mathrm{Bern}(\mathbf{y=0}|D(\mathbf{x}))] -\underset{P(\mathbf{x}|\mathbf{y=1})P(\mathbf{y=1})}{\mathbf{E}}[\log \mathrm{Bern}(\mathbf{y=1}|D(\mathbf{x}))]+ H(P(\mathbf{x}),Q(\mathbf{x}))\\
   &= -\pi\underset{P_d(\mathbf{x})}{\mathbf{E}}[\log(1 - D(\mathbf{x}))] -(1-\pi)\underset{P_g(\mathbf{x})}{\mathbf{E}}[\log D(\mathbf{x})]+ H(P(\mathbf{x}),Q(\mathbf{x}))\\
   &= -\pi\underset{P_d(\mathbf{x})}{\mathbf{E}}[\log(1 - D(\mathbf{x}))] -(1-\pi)\underset{P_g(\mathbf{x})}{\mathbf{E}}[\log D(\mathbf{x})]+ H(P(\mathbf{x}),Q(\mathbf{x}))\\
>>>>>>> 2783ffa775bb93c1c7f0aa2a2fefd9086c1ab936
